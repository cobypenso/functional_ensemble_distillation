{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "sys.path.append(\"../\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "from giung2.config import get_cfg\n",
    "from giung2.data.build import build_dataloaders\n",
    "from giung2.modeling.build import build_model\n",
    "from giung2.evaluation import (\n",
    "    evaluate_acc, evaluate_nll, evaluate_bs, evaluate_ece,\n",
    "    get_optimal_temperature,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_de_predictions(model, dataloader, ensemble_size, get_ith_weight_file):\n",
    "    true_labels = [] # [num_examples, ens_size, num_classes]\n",
    "    pred_logits = [] # [num_examples,]\n",
    "    for images, labels in dataloader:\n",
    "        images = images.cuda()\n",
    "        for idx in range(ensemble_size):\n",
    "            model.load_state_dict(\n",
    "                torch.load(\n",
    "                    get_ith_weight_file(idx), map_location=\"cpu\"\n",
    "                )[\"model_state_dict\"]\n",
    "            )\n",
    "            if idx == 0:\n",
    "                logits = model(images)[\"logits\"][:, None, :].cpu()\n",
    "            else:\n",
    "                logits = torch.cat([\n",
    "                    logits, model(images)[\"logits\"][:, None, :].cpu()\n",
    "                ], dim=1)\n",
    "        pred_logits.append(logits.cpu())\n",
    "        true_labels.append(labels.cpu())\n",
    "    return torch.cat(pred_logits), torch.cat(true_labels)\n",
    "\n",
    "\n",
    "def get_be_predictions(model, dataloader, ensemble_size):\n",
    "    true_labels = [] # [num_examples, ens_size, num_classes]\n",
    "    pred_logits = [] # [num_examples,]\n",
    "    for images, labels in dataloader:\n",
    "        images = images.cuda().repeat(ensemble_size, 1, 1, 1)\n",
    "        logits = model(images)[\"logits\"]\n",
    "        logits = torch.stack(\n",
    "            torch.split(logits, logits.size(0) // ensemble_size), dim=1\n",
    "        )\n",
    "        pred_logits.append(logits.cpu())\n",
    "        true_labels.append(labels.cpu())\n",
    "    return torch.cat(pred_logits), torch.cat(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRN28x10 on CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepEns-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label        ACC    NLL     BS    ECE    cNLL    cBS    cECE\n",
      "---------  -----  -----  -----  -----  ------  -----  ------\n",
      "DeepEns-1  80.22  0.789  0.282  0.042   0.789  0.282   0.041\n",
      "DeepEns-2  81.90  0.713  0.261  0.033   0.708  0.260   0.031\n",
      "DeepEns-3  82.46  0.684  0.253  0.032   0.673  0.251   0.027\n",
      "DeepEns-4  82.54  0.670  0.249  0.033   0.655  0.246   0.026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 4\n",
    "\n",
    "# load config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/C100_WRN28x10_SGD.yaml\", allow_unsafe=True)\n",
    "cfg.NUM_GPUS = 1\n",
    "\n",
    "# build model\n",
    "model = build_model(cfg).cuda().eval()\n",
    "\n",
    "# build dataloaders\n",
    "dataloaders = build_dataloaders(cfg, root=\"../datasets\")\n",
    "\n",
    "# configure path for deep ensembles\n",
    "get_ith_weight_file = lambda idx: os.path.join(f\"../outputs/C100_WRN28x10_SGD_{idx}\", \"best_acc1.pth.tar\")\n",
    "\n",
    "# disable grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# make predictions on valid split\n",
    "val_pred_logits, val_true_labels = get_de_predictions(\n",
    "    model, dataloaders[\"val_loader\"], ensemble_size, get_ith_weight_file\n",
    ")\n",
    "val_confidences = torch.softmax(val_pred_logits, dim=2)\n",
    "\n",
    "# make predictions on test split\n",
    "tst_pred_logits, tst_true_labels = get_de_predictions(\n",
    "    model, dataloaders[\"tst_loader\"], ensemble_size, get_ith_weight_file\n",
    ")\n",
    "tst_confidences = torch.softmax(tst_pred_logits, dim=2)\n",
    "\n",
    "# make evaluation results\n",
    "for e in range(ensemble_size):\n",
    "    t_opt = get_optimal_temperature(val_confidences[:, :e+1, :].mean(1), val_true_labels)\n",
    "    DATA.append([\n",
    "        f\"DeepEns-{e+1}\",\n",
    "        evaluate_acc(                  tst_confidences[:, :e+1, :].mean(1),                             tst_true_labels) * 100,\n",
    "        evaluate_nll(                  tst_confidences[:, :e+1, :].mean(1),                             tst_true_labels),\n",
    "        evaluate_bs(                   tst_confidences[:, :e+1, :].mean(1),                             tst_true_labels),\n",
    "        evaluate_ece(                  tst_confidences[:, :e+1, :].mean(1),                             tst_true_labels),\n",
    "        evaluate_nll(torch.log_softmax(tst_confidences[:, :e+1, :].mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "        evaluate_bs( torch.log_softmax(tst_confidences[:, :e+1, :].mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "        evaluate_ece(torch.log_softmax(tst_confidences[:, :e+1, :].mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    ])\n",
    "\n",
    "print(tabulate(DATA, headers=[\"Label\", \"ACC\", \"NLL\", \"BS\", \"ECE\", \"cNLL\", \"cBS\", \"cECE\",], floatfmt=[\"\", \".2f\",] + [\".3f\"] * 6))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchEns-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label              ACC    NLL     BS    ECE    cNLL    cBS    cECE\n",
      "---------------  -----  -----  -----  -----  ------  -----  ------\n",
      "DeepEns-1        80.22  0.789  0.282  0.042   0.789  0.282   0.041\n",
      "DeepEns-2        81.90  0.713  0.261  0.033   0.708  0.260   0.031\n",
      "DeepEns-3        82.46  0.684  0.253  0.032   0.673  0.251   0.027\n",
      "DeepEns-4        82.54  0.670  0.249  0.033   0.655  0.246   0.026\n",
      "BatchEns-4 (KD)  80.40  0.804  0.286  0.072   0.750  0.277   0.021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 4\n",
    "\n",
    "# load config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/C100_WRN28x10_BE4.yaml\", allow_unsafe=True)\n",
    "cfg.NUM_GPUS = 1\n",
    "\n",
    "# build model\n",
    "model = build_model(cfg).cuda().eval()\n",
    "model.load_state_dict(torch.load(\"../outputs/C100_WRN28x10_BE4_KD_0/best_acc1.pth.tar\", map_location=\"cpu\")[\"model_state_dict\"])\n",
    "\n",
    "# build dataloaders\n",
    "dataloaders = build_dataloaders(cfg, root=\"../datasets\")\n",
    "\n",
    "# disable grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# make predictions on valid split\n",
    "val_pred_logits, val_true_labels = get_be_predictions(model, dataloaders[\"val_loader\"], ensemble_size)\n",
    "val_confidences = torch.softmax(val_pred_logits, dim=2)\n",
    "\n",
    "t_opt = get_optimal_temperature(val_confidences.mean(1), val_true_labels)\n",
    "\n",
    "# make predictions on test split\n",
    "tst_pred_logits, tst_true_labels = get_be_predictions(model, dataloaders[\"tst_loader\"], ensemble_size)\n",
    "tst_confidences = torch.softmax(tst_pred_logits, dim=2)\n",
    "\n",
    "DATA.append([\n",
    "    \"BatchEns-4 (KD)\",\n",
    "    evaluate_acc(                  tst_confidences.mean(1),                             tst_true_labels) * 100,\n",
    "    evaluate_nll(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_bs(                   tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_ece(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_nll(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_bs( torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_ece(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "])\n",
    "\n",
    "print(tabulate(DATA, headers=[\"Label\", \"ACC\", \"NLL\", \"BS\", \"ECE\", \"cNLL\", \"cBS\", \"cECE\",], floatfmt=[\"\", \".2f\",] + [\".3f\"] * 6))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                         ACC    NLL     BS    ECE    cNLL    cBS    cECE\n",
      "--------------------------  -----  -----  -----  -----  ------  -----  ------\n",
      "DeepEns-1                   80.22  0.789  0.282  0.042   0.789  0.282   0.041\n",
      "DeepEns-2                   81.90  0.713  0.261  0.033   0.708  0.260   0.031\n",
      "DeepEns-3                   82.46  0.684  0.253  0.032   0.673  0.251   0.027\n",
      "DeepEns-4                   82.54  0.670  0.249  0.033   0.655  0.246   0.026\n",
      "BatchEns-4 (KD)             80.40  0.804  0.286  0.072   0.750  0.277   0.021\n",
      "BatchEns-4 (KD + Gaussian)  80.04  0.816  0.288  0.075   0.760  0.277   0.020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 4\n",
    "\n",
    "# load config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/C100_WRN28x10_BE4.yaml\", allow_unsafe=True)\n",
    "cfg.NUM_GPUS = 1\n",
    "\n",
    "# build model\n",
    "model = build_model(cfg).cuda().eval()\n",
    "model.load_state_dict(torch.load(\"../outputs/C100_WRN28x10_BE4_KDGaussian_0/best_acc1.pth.tar\", map_location=\"cpu\")[\"model_state_dict\"])\n",
    "\n",
    "# build dataloaders\n",
    "dataloaders = build_dataloaders(cfg, root=\"../datasets\")\n",
    "\n",
    "# disable grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# make predictions on valid split\n",
    "val_pred_logits, val_true_labels = get_be_predictions(model, dataloaders[\"val_loader\"], ensemble_size)\n",
    "val_confidences = torch.softmax(val_pred_logits, dim=2)\n",
    "\n",
    "t_opt = get_optimal_temperature(val_confidences.mean(1), val_true_labels)\n",
    "\n",
    "# make predictions on test split\n",
    "tst_pred_logits, tst_true_labels = get_be_predictions(model, dataloaders[\"tst_loader\"], ensemble_size)\n",
    "tst_confidences = torch.softmax(tst_pred_logits, dim=2)\n",
    "\n",
    "DATA.append([\n",
    "    \"BatchEns-4 (KD + Gaussian)\",\n",
    "    evaluate_acc(                  tst_confidences.mean(1),                             tst_true_labels) * 100,\n",
    "    evaluate_nll(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_bs(                   tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_ece(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_nll(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_bs( torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_ece(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "])\n",
    "\n",
    "print(tabulate(DATA, headers=[\"Label\", \"ACC\", \"NLL\", \"BS\", \"ECE\", \"cNLL\", \"cBS\", \"cECE\",], floatfmt=[\"\", \".2f\",] + [\".3f\"] * 6))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                         ACC    NLL     BS    ECE    cNLL    cBS    cECE\n",
      "--------------------------  -----  -----  -----  -----  ------  -----  ------\n",
      "DeepEns-1                   80.22  0.789  0.282  0.042   0.789  0.282   0.041\n",
      "DeepEns-2                   81.90  0.713  0.261  0.033   0.708  0.260   0.031\n",
      "DeepEns-3                   82.46  0.684  0.253  0.032   0.673  0.251   0.027\n",
      "DeepEns-4                   82.54  0.670  0.249  0.033   0.655  0.246   0.026\n",
      "BatchEns-4 (KD)             80.40  0.804  0.286  0.072   0.750  0.277   0.021\n",
      "BatchEns-4 (KD + Gaussian)  80.04  0.816  0.288  0.075   0.760  0.277   0.020\n",
      "BatchEns-4 (KD + ODS)       81.92  0.685  0.258  0.026   0.682  0.258   0.026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 4\n",
    "\n",
    "# load config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/C100_WRN28x10_BE4.yaml\", allow_unsafe=True)\n",
    "cfg.NUM_GPUS = 1\n",
    "\n",
    "# build model\n",
    "model = build_model(cfg).cuda().eval()\n",
    "model.load_state_dict(torch.load(\"../outputs/C100_WRN28x10_BE4_KDODS_0/best_acc1.pth.tar\", map_location=\"cpu\")[\"model_state_dict\"])\n",
    "\n",
    "# build dataloaders\n",
    "dataloaders = build_dataloaders(cfg, root=\"../datasets\")\n",
    "\n",
    "# disable grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# make predictions on valid split\n",
    "val_pred_logits, val_true_labels = get_be_predictions(model, dataloaders[\"val_loader\"], ensemble_size)\n",
    "val_confidences = torch.softmax(val_pred_logits, dim=2)\n",
    "\n",
    "t_opt = get_optimal_temperature(val_confidences.mean(1), val_true_labels)\n",
    "\n",
    "# make predictions on test split\n",
    "tst_pred_logits, tst_true_labels = get_be_predictions(model, dataloaders[\"tst_loader\"], ensemble_size)\n",
    "tst_confidences = torch.softmax(tst_pred_logits, dim=2)\n",
    "\n",
    "DATA.append([\n",
    "    \"BatchEns-4 (KD + ODS)\",\n",
    "    evaluate_acc(                  tst_confidences.mean(1),                             tst_true_labels) * 100,\n",
    "    evaluate_nll(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_bs(                   tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_ece(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_nll(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_bs( torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_ece(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "])\n",
    "\n",
    "print(tabulate(DATA, headers=[\"Label\", \"ACC\", \"NLL\", \"BS\", \"ECE\", \"cNLL\", \"cBS\", \"cECE\",], floatfmt=[\"\", \".2f\",] + [\".3f\"] * 6))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label                         ACC    NLL     BS    ECE    cNLL    cBS    cECE\n",
      "--------------------------  -----  -----  -----  -----  ------  -----  ------\n",
      "DeepEns-1                   80.22  0.789  0.282  0.042   0.789  0.282   0.041\n",
      "DeepEns-2                   81.90  0.713  0.261  0.033   0.708  0.260   0.031\n",
      "DeepEns-3                   82.46  0.684  0.253  0.032   0.673  0.251   0.027\n",
      "DeepEns-4                   82.54  0.670  0.249  0.033   0.655  0.246   0.026\n",
      "BatchEns-4 (KD)             80.40  0.804  0.286  0.072   0.750  0.277   0.021\n",
      "BatchEns-4 (KD + Gaussian)  80.04  0.816  0.288  0.075   0.760  0.277   0.020\n",
      "BatchEns-4 (KD + ODS)       81.92  0.685  0.258  0.026   0.682  0.258   0.026\n",
      "BatchEns-4 (KD + ConfODS)   82.25  0.670  0.253  0.023   0.665  0.252   0.023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_size = 4\n",
    "\n",
    "# load config file\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"../configs/C100_WRN28x10_BE4.yaml\", allow_unsafe=True)\n",
    "cfg.NUM_GPUS = 1\n",
    "\n",
    "# build model\n",
    "model = build_model(cfg).cuda().eval()\n",
    "model.load_state_dict(torch.load(\"../outputs/C100_WRN28x10_BE4_KDConfODS_0/best_acc1.pth.tar\", map_location=\"cpu\")[\"model_state_dict\"])\n",
    "\n",
    "# build dataloaders\n",
    "dataloaders = build_dataloaders(cfg, root=\"../datasets\")\n",
    "\n",
    "# disable grad\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# make predictions on valid split\n",
    "val_pred_logits, val_true_labels = get_be_predictions(model, dataloaders[\"val_loader\"], ensemble_size)\n",
    "val_confidences = torch.softmax(val_pred_logits, dim=2)\n",
    "\n",
    "t_opt = get_optimal_temperature(val_confidences.mean(1), val_true_labels)\n",
    "\n",
    "# make predictions on test split\n",
    "tst_pred_logits, tst_true_labels = get_be_predictions(model, dataloaders[\"tst_loader\"], ensemble_size)\n",
    "tst_confidences = torch.softmax(tst_pred_logits, dim=2)\n",
    "\n",
    "DATA.append([\n",
    "    \"BatchEns-4 (KD + ConfODS)\",\n",
    "    evaluate_acc(                  tst_confidences.mean(1),                             tst_true_labels) * 100,\n",
    "    evaluate_nll(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_bs(                   tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_ece(                  tst_confidences.mean(1),                             tst_true_labels),\n",
    "    evaluate_nll(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_bs( torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "    evaluate_ece(torch.log_softmax(tst_confidences.mean(1).log() / t_opt, dim=1).exp(), tst_true_labels),\n",
    "])\n",
    "\n",
    "print(tabulate(DATA, headers=[\"Label\", \"ACC\", \"NLL\", \"BS\", \"ECE\", \"cNLL\", \"cBS\", \"cECE\",], floatfmt=[\"\", \".2f\",] + [\".3f\"] * 6))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06a372ff30a702c1a07b87ff2ca21a9c947b3ad6b0fdd9c07b2cc1ab1f624530"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('giung-tc1.9.0-cuda11.1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
